---
title: "OSUN R Users Community"
subtitle: "Kevin O'Brien"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      countIncrementalSlides: false
---

### Regression Diagnostics:avPlots

#### <tt>avPlots</tt>

*  Graphs outcome vs predictor variables holding the rest constant (also called partial-regression plots)
*  Help identify the effect(or influence) of an observation on the regression coefficient of the predictor variable

---

### Regression Diagnostics:avPlots

```{r eval=FALSE}
library(car)
reg1 <-lm(prestige ~ education + income + type, data = Prestige)
avPlots(reg1)

```
---

### Regression Diagnostics:avPlots

```{r echo=FALSE,message=FALSE,warning=FALSE}
library(car)
reg1 <-lm(prestige ~ education + income + type, data = Prestige)
avPlots(reg1)

```
---

### Regression Diagnostics: <tt>influenceIndexPlot()</tt>


#### <tt>influenceIndexPlot()</tt>

*  Cook's distance measures how much an observation influences the overall model or predicted values
*  Studentizided residuals are the residuals divided by their estimated standard deviation as a way to standardized
*  Bonferronitest to identify outliers
*  Hat-points identify influential observations (have a high impact on the predictor variables)


---

### Regression Diagnostics: <tt>influenceIndexPlot()</tt>


#### <tt>influenceIndexPlot()</tt>

```{r eval=FALSE}
library(car)
reg1 <-lm(prestige ~ education + income + type, data = Prestige)
influenceIndexPlot(reg1)

```

---

### Regression Diagnostics: <tt>influenceIndexPlot()</tt>


#### <tt>influenceIndexPlot()</tt>

```{r echo=FALSE,message=FALSE,warning=FALSE}
library(car)
reg1 <-lm(prestige ~ education + income + type, data = Prestige)
influenceIndexPlot(reg1)

```



---

#### `influencePlot`

*  <tt>influencePlot()</tt> creates a bubble-plot combining the display of Studentizedresiduals, hat-values, and Cook's distance (represented in the circles).



```{r eval=FALSE }
library(car)
reg1 <-lm(prestige ~ education + income + type, data = Prestige)
influencePlot(reg1)
```

---


```{r echo=FALSE,message=FALSE,warning=FALSE}
library(car)
reg1 <-lm(prestige ~ education + income + type, data = Prestige)
influencePlot(reg1)
```

---
### Alcohol and Tobacco Data

This example is for exposition only. We will ignore the fact that this may not be a great way of modeling the this particular set of data!


```{r}


alctob <- data.frame( cbind(
Alcohol = c(6.47, 6.13, 6.19, 4.89, 5.63, 4.52, 
            5.89, 4.79, 5.27, 6.08, 4.02),
Tobacco = c(4.03, 3.76, 3.77, 3.34, 3.47, 2.92, 
            3.20, 2.71, 3.53, 4.51, 4.56)),
row.names = c("North", "Yorkshire", "Northeast", 
"East Midlands", "West Midlands", "East Anglia", 
"Southeast", "Southwest", "Wales", 
"Scotland", "N. Ireland"))


```

---


```{r echo=FALSE }
alctobwo <- subset(alctob,rownames(alctob)!="N. Ireland") 
#without North Ireland

plot(alctob$Tobacco, alctob$Alcohol,
main="Weekly Household Spending on Alcohol vs. Tobacco",
xlab="Tobacco Spending (GBP)",
ylab="Alcohol Spending (GBP)",
pch=16,col="red",cex=1.5,font.lab=2) 
#note N. Ireland in the bottom-right

```

---

```{r}
fit1 <- lm( Alcohol ~ Tobacco, data = alctob)
fit2 <- lm( Alcohol ~ Tobacco, data = alctobwo)
```

---

All Observations


```{r}
summary(fit1)


```
---

Outlier Removed

```{r}

summary(fit2)



```
---


### Outliers



The conservative outlier test uses the
Bonferonni inequality to calculate the p-values we associate with the
Student's-t test. 

In R, we can use the <tt>outlierTest()</tt> command to perform this
test on our model. 

Remember that when we test for influence, we are testing
the effect of an observation on model coefficients. 

---

Therefore we need to
give the <tt>outlierTest</tt> command a linear model as its input.

```{r}
outlierTest(fit1)
 
```

---

We can also use R to calculate Cook's distance. 
Here we label any observation with Cook's distance greater than 1 as influential.

```{r}
cooks.distance(fit1)

```

---

### Influence Plots


Finally, one of the easier ways to evaluate our residuals and look for
for influential points is through plots. 


```{r ,out.width = "80%" }
#qq plot for studentized resid 
qqPlot(fit1, main="QQ Plot",pch=18, lim=c(-3,2)) 
```


---

### Influence Plots


```{r ,out.width = "80%" }
# leverage plots
leveragePlots(fit1) 
```



```{r, echo=FALSE,message=FALSE,warning=FALSE}
fit <- fit1
```


---

### Influence Plots

```{r eval=FALSE}

# Influential Observations
# added variable plots 
avPlots(fit1)

```

---

### Influence Plots

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Influential Observations
# Influential Observations
# added variable plots 
avPlots(fit1)

```
---

### Influence Plots

```{r eval=FALSE}
# Cook's D plot
# identify D values > 4/(n-k-1) 
cutoff <- 4/((nrow(mtcars)-length(fit1$coefficients)-2)) 
plot(fit, which=4, cook.levels=cutoff)

```

---

### Influence Plots

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Cook's D plot
# identify D values > 4/(n-k-1) 
cutoff <- 4/((nrow(mtcars)-length(fit1$coefficients)-2)) 
plot(fit, which=4, cook.levels=cutoff)

```

---

### Influence Plots

```{r eval=FALSE}
# Influence Plot 
influencePlot(fit1,id.method="identify", 
main="Influence Plot", 
col="red",
sub="Circle size is proportial to Cook's Distance" )

```
---

### Influence Plots

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Influence Plot 
influencePlot(fit1,id.method="identify", 
main="Influence Plot", 
col="red",
sub="Circle size is proportial to Cook's Distance" )

```
---



### Non-constant Error Variance


```{r}


# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(fit)
```

---

### Non-constant Error Variance

```{r eval=FALSE}
# plot studentized residuals vs. fitted values 
spreadLevelPlot(fit)
```

---

### Non-constant Error Variance

```{r echo=FALSE,message=FALSE,warning=FALSE}
# plot studentized residuals vs. fitted values 
spreadLevelPlot(fit)
```

---